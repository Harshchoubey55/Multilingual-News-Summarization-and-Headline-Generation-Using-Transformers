{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshchoubey55/Multilingual-News-Summarization-and-Headline-Generation-Using-Transformers/blob/main/TextSummarizationUsingTransferLearning(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFYT78ToxdWt"
      },
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "!pip install transformers datasets nltk --quiet\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Import modules\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# Load summarization model\n",
        "summarizer_model = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(summarizer_model)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(summarizer_model)\n",
        "\n",
        "# Load translation pipeline (English → Selected Language)\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-mul\")\n",
        "\n",
        "# Load CNN/DailyMail dataset (3% test sample)\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:3%]\")\n",
        "\n",
        "# Summarization\n",
        "def summarize(text, max_len=150, min_len=40, num_beams=4):\n",
        "    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_len, min_length=min_len,\n",
        "                                 length_penalty=2.0, num_beams=num_beams, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Hook generator\n",
        "def generate_hook(summary):\n",
        "    prompt = f\"Generate a catchy headline for: {summary}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    output_ids = model.generate(inputs[\"input_ids\"], max_length=20, min_length=5, num_beams=5,\n",
        "                                length_penalty=1.5, early_stopping=True)\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Translate summary/hook to selected language\n",
        "def translate_text(text, target_lang=\"hi\"):\n",
        "    # Target codes: \"hi\" → Hindi, \"fr\" → French, \"es\" → Spanish, \"de\" → German, etc.\n",
        "    translated = translator(text, tgt_lang=target_lang)[0]['translation_text']\n",
        "    return translated\n",
        "\n",
        "# Process\n",
        "articles = dataset[\"article\"][:5]\n",
        "actual_summaries = dataset[\"highlights\"][:5]\n",
        "generated_summaries = [summarize(article) for article in articles]\n",
        "generated_hooks = [generate_hook(summary) for summary in generated_summaries]\n",
        "\n",
        "# Set target language for translation\n",
        "target_lang_code = \"hi\"  # Change to \"fr\", \"es\", \"de\", etc.\n",
        "\n",
        "# Translate results\n",
        "translated_summaries = [translate_text(summary, target_lang_code) for summary in generated_summaries]\n",
        "translated_hooks = [translate_text(hook, target_lang_code) for hook in generated_hooks]\n",
        "\n",
        "# Show samples\n",
        "for i in range(3):\n",
        "    print(f\"\\nArticle #{i+1} (truncated):\\n{articles[i][:300]}...\")\n",
        "    print(f\"\\nGenerated Summary:\\n{generated_summaries[i]}\")\n",
        "    print(f\"Hook Headline:\\n {generated_hooks[i]}\")\n",
        "    print(f\"Translated Summary ({target_lang_code}):\\n{translated_summaries[i]}\")\n",
        "    print(f\"Translated Hook ({target_lang_code}):\\n{translated_hooks[i]}\")\n",
        "    print(f\"\\nActual Summary:\\n{actual_summaries[i]}\")\n",
        "    print(\"=\"*100)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}